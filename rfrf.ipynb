{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Bengaluru_House_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13320, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_type\n",
       "Built-up  Area          2418\n",
       "Carpet  Area              87\n",
       "Plot  Area              2025\n",
       "Super built-up  Area    8790\n",
       "Name: area_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('area_type')['area_type'].agg('count')  # to aggregate the data based on area_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop few column that is not affecting the price of the house\n",
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location       1\n",
       "size          16\n",
       "total_sqft     0\n",
       "bath          73\n",
       "price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91993\\AppData\\Local\\Temp\\ipykernel_24972\\1100308896.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n"
     ]
    }
   ],
   "source": [
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>bhk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Yelahanka</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>2100 - 2850</td>\n",
       "      <td>4.0</td>\n",
       "      <td>186.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Hebbal</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>3067 - 8156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>477.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>8th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1042 - 1105</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Sarjapur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1145 - 1340</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>KR Puram</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1015 - 1540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Kengeri</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>34.46Sq. Meter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1195 - 1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.770</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Arekere</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>4125Perch</td>\n",
       "      <td>9.0</td>\n",
       "      <td>265.000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Yelahanka</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1120 - 1145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Bettahalsoor</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>3090 - 5002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>445.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               location       size      total_sqft  bath    price  bhk\n",
       "30            Yelahanka      4 BHK     2100 - 2850   4.0  186.000    4\n",
       "122              Hebbal      4 BHK     3067 - 8156   4.0  477.000    4\n",
       "137  8th Phase JP Nagar      2 BHK     1042 - 1105   2.0   54.005    2\n",
       "165            Sarjapur      2 BHK     1145 - 1340   2.0   43.490    2\n",
       "188            KR Puram      2 BHK     1015 - 1540   2.0   56.800    2\n",
       "410             Kengeri      1 BHK  34.46Sq. Meter   1.0   18.500    1\n",
       "549         Hennur Road      2 BHK     1195 - 1440   2.0   63.770    2\n",
       "648             Arekere  9 Bedroom       4125Perch   9.0  265.000    9\n",
       "661           Yelahanka      2 BHK     1120 - 1145   2.0   48.130    2\n",
       "672        Bettahalsoor  4 Bedroom     3090 - 5002   4.0  445.000    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df3[~df3['total_sqft'].apply(is_float)].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location      Yelahanka\n",
       "size              4 BHK\n",
       "total_sqft       2475.0\n",
       "bath                4.0\n",
       "price             186.0\n",
       "bhk                   4\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# for rest kind i m ignoring them \n",
    "df4 = df3.copy()  # making a deep copy of the dataframe\n",
    "df4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)\n",
    "df4.loc[30]  # to check the 30th row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91993\\AppData\\Local\\Temp\\ipykernel_24972\\1107562097.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "df1.shape\n",
    "\n",
    "df1.groupby('area_type')['area_type'].agg('count')  # to aggregate the data based on area_type\n",
    "\n",
    "\n",
    "# to drop few column that is not affecting the price of the house\n",
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "\n",
    "\n",
    "# DATA CLEANING PROCESS\n",
    "\n",
    "# show the number of rows having null values\n",
    "df2.isnull().sum()  \n",
    "\n",
    "# drop the rows having null values\n",
    "df3 = df2.dropna()\n",
    "\n",
    "# In the size column there are some values in BHK and some in Bedroom. So we need to convert all to BHK\n",
    "# to see how many unique columns are there\n",
    "df3['size'].unique()\n",
    "\n",
    "# making a new column BHK \n",
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "# the total sq feet column is also in range so we need to convert it to a single value replacing it with average value\n",
    "# making a function just to check whether it is a float or not , if not then carry the average of it \n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df3[~df3['total_sqft'].apply(is_float)].head(10)  # came to know along with range it has sq.meter , perch , etc\n",
    "\n",
    "# for range \n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# for rest kind i m ignoring them \n",
    "df4 = df3.copy()  # making a deep copy of the dataframe\n",
    "df4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)\n",
    "df4.loc[30]  # to check the 30th row of the dataframe\n",
    "\n",
    "\n",
    "# FEATURE ENGINEERING AND DIMENSIONALITY REDUCTION\n",
    "\n",
    "# doing price per sq_feet\n",
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "\n",
    "\n",
    "# working on location points \n",
    "len(df5.location.unique())  # to check the unique values of location i.e. 1305 means with one hot encoding it will have 1305 columns so dropping few\n",
    "df5.location  = df5.location.apply(lambda x:x.strip())  # it will strip the name from left and right side\n",
    "location_stats = df5['location'].value_counts(ascending = False)  # sort the data into descending order \n",
    "location_less_than_10 = location_stats[location_stats<=10]  # taking the location which has less than 10 data points\n",
    "df5.location = df5.location.apply(lambda x: 'other' if x in location_less_than_10 else x)  # replacing the location with other if it has less than 10 data points\n",
    "len(df5.location.unique())  # 242\n",
    "\n",
    "\n",
    "# OUTLIER DETECTION\n",
    "# size with the square_ft -> so less than 300 will be rejected \n",
    "df6 = df5[~(df5.total_sqft/df5.bhk<300)]  # removing the data points which has less than 300 sqft per bhk\n",
    "\n",
    "# to remove the extreme cases of price per sqft like very high and very low price .\n",
    "# That can be done by grouping the dataframe and the calculate the mean and std for each location and upto 1 std we can take it .\n",
    "def remove_pps_outlier(df):\n",
    "    df_out = pd.DataFrame()  # it is made to return a dataframe that satisfy the condition\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))] # keep upto 1 std\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True) # add it with df_out dataframe\n",
    "    return df_out\n",
    "\n",
    "df7 = remove_pps_outlier(df6)\n",
    "\n",
    "\n",
    "\n",
    "# Now the issue is the 2BHK has more price than 3BHK in some cases so we need to remove those outliers\n",
    "# we can do that by plotting the scatter plot of 2BHK and 3BHK and then remove the outliers\n",
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "\n",
    "# now for every location  , we will remove the outliers -> 2BHK mean should be greater than 1BHK mean \n",
    "def remove_bhk_outlier(df):\n",
    "    exclude_indices = np.array([]) # to store the indices of the data points that are to be removed\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        # the below for loop will give the mean and std of the price per sqft for each bhk\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "\n",
    "        # it will add if the mean value is less than estimate mean\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "\n",
    "\n",
    "df8 = remove_bhk_outlier(df7)\n",
    "\n",
    "\n",
    "\n",
    "# to remove the bathrooms like 2 bedrooms and 4 bathrooms \n",
    "df9 = df8[ df8.bath < df8.bhk+2 ]\n",
    "\n",
    "# now droping the extra columns that are made for price estimation or for cleanung purpose\n",
    "df9 = df9.drop(['price_per_sqft'] , axis= 'columns')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For categorial data , like location doing one hot encoding\n",
    "dummies = pd.get_dummies(df9.location)\n",
    "\n",
    "df10 = pd.concat([df9,dummies],axis='columns')\n",
    "# to avoid dummy variable trap\n",
    "df11 = df10.drop(['other'],axis='columns')\n",
    "# since dummies are made so we can drop the location column\n",
    "df11 = df10.drop(['location'],axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "# Model making\n",
    "X = df11.drop(['price'],axis='columns')\n",
    "y = df11.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>bhk</th>\n",
       "      <th>1st Block Jayanagar</th>\n",
       "      <th>1st Phase JP Nagar</th>\n",
       "      <th>2nd Phase Judicial Layout</th>\n",
       "      <th>2nd Stage Nagarbhavi</th>\n",
       "      <th>5th Block Hbr Layout</th>\n",
       "      <th>...</th>\n",
       "      <th>Vishveshwarya Layout</th>\n",
       "      <th>Vishwapriya Layout</th>\n",
       "      <th>Vittasandra</th>\n",
       "      <th>Whitefield</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "      <th>Yelahanka</th>\n",
       "      <th>Yelahanka New Town</th>\n",
       "      <th>Yelenahalli</th>\n",
       "      <th>Yeshwanthpur</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 BHK</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 BHK</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>1 BHK</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>2 BHK</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>1 Bedroom</td>\n",
       "      <td>812.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>4 BHK</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7251 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            size  total_sqft  bath  price  bhk  1st Block Jayanagar  \\\n",
       "0          4 BHK      2850.0   4.0  428.0    4                 True   \n",
       "1          3 BHK      1630.0   3.0  194.0    3                 True   \n",
       "2          3 BHK      1875.0   2.0  235.0    3                 True   \n",
       "3          3 BHK      1200.0   2.0  130.0    3                 True   \n",
       "4          2 BHK      1235.0   2.0  148.0    2                 True   \n",
       "...          ...         ...   ...    ...  ...                  ...   \n",
       "10232      2 BHK      1200.0   2.0   70.0    2                False   \n",
       "10233      1 BHK      1800.0   1.0  200.0    1                False   \n",
       "10236      2 BHK      1353.0   2.0  110.0    2                False   \n",
       "10237  1 Bedroom       812.0   1.0   26.0    1                False   \n",
       "10240      4 BHK      3600.0   5.0  400.0    4                False   \n",
       "\n",
       "       1st Phase JP Nagar  2nd Phase Judicial Layout  2nd Stage Nagarbhavi  \\\n",
       "0                   False                      False                 False   \n",
       "1                   False                      False                 False   \n",
       "2                   False                      False                 False   \n",
       "3                   False                      False                 False   \n",
       "4                   False                      False                 False   \n",
       "...                   ...                        ...                   ...   \n",
       "10232               False                      False                 False   \n",
       "10233               False                      False                 False   \n",
       "10236               False                      False                 False   \n",
       "10237               False                      False                 False   \n",
       "10240               False                      False                 False   \n",
       "\n",
       "       5th Block Hbr Layout  ...  Vishveshwarya Layout  Vishwapriya Layout  \\\n",
       "0                     False  ...                 False               False   \n",
       "1                     False  ...                 False               False   \n",
       "2                     False  ...                 False               False   \n",
       "3                     False  ...                 False               False   \n",
       "4                     False  ...                 False               False   \n",
       "...                     ...  ...                   ...                 ...   \n",
       "10232                 False  ...                 False               False   \n",
       "10233                 False  ...                 False               False   \n",
       "10236                 False  ...                 False               False   \n",
       "10237                 False  ...                 False               False   \n",
       "10240                 False  ...                 False               False   \n",
       "\n",
       "       Vittasandra  Whitefield  Yelachenahalli  Yelahanka  Yelahanka New Town  \\\n",
       "0            False       False           False      False               False   \n",
       "1            False       False           False      False               False   \n",
       "2            False       False           False      False               False   \n",
       "3            False       False           False      False               False   \n",
       "4            False       False           False      False               False   \n",
       "...            ...         ...             ...        ...                 ...   \n",
       "10232        False       False           False      False               False   \n",
       "10233        False       False           False      False               False   \n",
       "10236        False       False           False      False               False   \n",
       "10237        False       False           False      False               False   \n",
       "10240        False       False           False      False               False   \n",
       "\n",
       "       Yelenahalli  Yeshwanthpur  other  \n",
       "0            False         False  False  \n",
       "1            False         False  False  \n",
       "2            False         False  False  \n",
       "3            False         False  False  \n",
       "4            False         False  False  \n",
       "...            ...           ...    ...  \n",
       "10232        False         False   True  \n",
       "10233        False         False   True  \n",
       "10236        False         False   True  \n",
       "10237        False         False   True  \n",
       "10240        False         False   True  \n",
       "\n",
       "[7251 rows x 247 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452277697873589"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model making\n",
    "X = df11.drop(['price', 'size'], axis='columns')\n",
    "y = df11.price\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82430186, 0.77166234, 0.85089567, 0.80837764, 0.83653286])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit      # it will basically divide the data randomly into parts that made for cross_validation\n",
    "from sklearn.model_selection import cross_val_score   \n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model  best_score  \\\n",
      "0  linear_regression    0.821712   \n",
      "1              lasso    0.806624   \n",
      "2      decision_tree    0.766527   \n",
      "\n",
      "                                         best_params  \n",
      "0          {'fit_intercept': True, 'positive': True}  \n",
      "1                {'alpha': 1, 'selection': 'cyclic'}  \n",
      "2  {'criterion': 'squared_error', 'splitter': 'be...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                # Removed 'normalize', as it's not valid anymore\n",
    "                'fit_intercept': [True, False],\n",
    "                'positive': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['squared_error', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X_scaled, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "\n",
    "\n",
    "# Example usage\n",
    "best_model_results = find_best_model_using_gridsearchcv(X, y)\n",
    "print(best_model_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(181.27815484010847)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume that the linear Regression is giving u the best result\n",
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]\n",
    "\n",
    "\n",
    "predict_price('1st Phase JP Nagar',1000, 2, 2)  \n",
    "predict_price('1st Phase JP Nagar',1000, 3, 3)\n",
    "predict_price('Indira Nagar',1000, 2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91993\\AppData\\Local\\Temp\\ipykernel_27932\\2933816033.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model  best_score  \\\n",
      "0  linear_regression    0.821712   \n",
      "1              lasso    0.806624   \n",
      "2      decision_tree    0.777912   \n",
      "\n",
      "                                         best_params  \n",
      "0          {'fit_intercept': True, 'positive': True}  \n",
      "1                {'alpha': 1, 'selection': 'cyclic'}  \n",
      "2  {'criterion': 'squared_error', 'splitter': 'ra...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\91993\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "df1.shape\n",
    "\n",
    "df1.groupby('area_type')['area_type'].agg('count')  # to aggregate the data based on area_type\n",
    "\n",
    "\n",
    "# to drop few column that is not affecting the price of the house\n",
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "\n",
    "\n",
    "# DATA CLEANING PROCESS\n",
    "\n",
    "# show the number of rows having null values\n",
    "df2.isnull().sum()  \n",
    "\n",
    "# drop the rows having null values\n",
    "df3 = df2.dropna()\n",
    "\n",
    "# In the size column there are some values in BHK and some in Bedroom. So we need to convert all to BHK\n",
    "# to see how many unique columns are there\n",
    "df3['size'].unique()\n",
    "\n",
    "# making a new column BHK \n",
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "# the total sq feet column is also in range so we need to convert it to a single value replacing it with average value\n",
    "# making a function just to check whether it is a float or not , if not then carry the average of it \n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df3[~df3['total_sqft'].apply(is_float)].head(10)  # came to know along with range it has sq.meter , perch , etc\n",
    "\n",
    "# for range \n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# for rest kind i m ignoring them \n",
    "df4 = df3.copy()  # making a deep copy of the dataframe\n",
    "df4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)\n",
    "df4.loc[30]  # to check the 30th row of the dataframe\n",
    "\n",
    "\n",
    "# FEATURE ENGINEERING AND DIMENSIONALITY REDUCTION\n",
    "\n",
    "# doing price per sq_feet\n",
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "\n",
    "\n",
    "# working on location points \n",
    "len(df5.location.unique())  # to check the unique values of location i.e. 1305 means with one hot encoding it will have 1305 columns so dropping few\n",
    "df5.location  = df5.location.apply(lambda x:x.strip())  # it will strip the name from left and right side\n",
    "location_stats = df5['location'].value_counts(ascending = False)  # sort the data into descending order \n",
    "location_less_than_10 = location_stats[location_stats<=10]  # taking the location which has less than 10 data points\n",
    "df5.location = df5.location.apply(lambda x: 'other' if x in location_less_than_10 else x)  # replacing the location with other if it has less than 10 data points\n",
    "len(df5.location.unique())  # 242\n",
    "\n",
    "\n",
    "# OUTLIER DETECTION\n",
    "# size with the square_ft -> so less than 300 will be rejected \n",
    "df6 = df5[~(df5.total_sqft/df5.bhk<300)]  # removing the data points which has less than 300 sqft per bhk\n",
    "\n",
    "# to remove the extreme cases of price per sqft like very high and very low price .\n",
    "# That can be done by grouping the dataframe and the calculate the mean and std for each location and upto 1 std we can take it .\n",
    "def remove_pps_outlier(df):\n",
    "    df_out = pd.DataFrame()  # it is made to return a dataframe that satisfy the condition\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))] # keep upto 1 std\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True) # add it with df_out dataframe\n",
    "    return df_out\n",
    "\n",
    "df7 = remove_pps_outlier(df6)\n",
    "\n",
    "\n",
    "\n",
    "# Now the issue is the 2BHK has more price than 3BHK in some cases so we need to remove those outliers\n",
    "# we can do that by plotting the scatter plot of 2BHK and 3BHK and then remove the outliers\n",
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "\n",
    "# now for every location  , we will remove the outliers -> 2BHK mean should be greater than 1BHK mean \n",
    "def remove_bhk_outlier(df):\n",
    "    exclude_indices = np.array([]) # to store the indices of the data points that are to be removed\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        # the below for loop will give the mean and std of the price per sqft for each bhk\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "\n",
    "        # it will add if the mean value is less than estimate mean\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "\n",
    "\n",
    "df8 = remove_bhk_outlier(df7)\n",
    "\n",
    "\n",
    "\n",
    "# to remove the bathrooms like 2 bedrooms and 4 bathrooms \n",
    "df9 = df8[ df8.bath < df8.bhk+2 ]\n",
    "\n",
    "# now droping the extra columns that are made for price estimation or for cleanung purpose\n",
    "df9 = df9.drop(['price_per_sqft'] , axis= 'columns')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For categorial data , like location doing one hot encoding\n",
    "dummies = pd.get_dummies(df9.location)\n",
    "\n",
    "df10 = pd.concat([df9,dummies],axis='columns')\n",
    "# to avoid dummy variable trap\n",
    "df11 = df10.drop(['other'],axis='columns')\n",
    "# since dummies are made so we can drop the location column\n",
    "df11 = df10.drop(['location'],axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "# Model making\n",
    "X = df11.drop(['price', 'size'], axis='columns')\n",
    "y = df11.price\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)\n",
    "\n",
    "# we will use k fold cross validation to measure the accuracy of our LinearRegression model\n",
    "from sklearn.model_selection import ShuffleSplit      # it will basically divide the data randomly into parts that made for cross_validation\n",
    "from sklearn.model_selection import cross_val_score   \n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n",
    "\n",
    "\n",
    "\n",
    "# now we will try other models like Lasso and DecisionTreeRegressor by using GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                # Removed 'normalize', as it's not valid anymore\n",
    "                'fit_intercept': [True, False],\n",
    "                'positive': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['squared_error', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X_scaled, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "\n",
    "\n",
    "# Example usage\n",
    "best_model_results = find_best_model_using_gridsearchcv(X, y)\n",
    "print(best_model_results)\n",
    "\n",
    "\n",
    "# Assume that the linear Regression is giving u the best result\n",
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]\n",
    "\n",
    "\n",
    "predict_price('1st Phase JP Nagar',1000, 2, 2)  \n",
    "predict_price('1st Phase JP Nagar',1000, 3, 3)\n",
    "predict_price('Indira Nagar',1000, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Export the tested model to a pickle file and it will be used by python flask server\n",
    "import pickle\n",
    "with open('banglore_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)  # .dump( model , file)\n",
    "\n",
    "\n",
    "# for storing the columns that are used in the model\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))  # .dumps( data , file)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
